{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a54f82d2-e8de-46be-afcf-391901c97707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import torch\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "MARGIN_SIZE = 32\n",
    "HIDDEN_UNITS = 96\n",
    "TRANSFORM_DATA_SIZE = (64, 64)\n",
    "\n",
    "LETTERS_TRANSFORM = transforms.Compose([\n",
    "\ttransforms.Grayscale(num_output_channels=3),\n",
    "\ttransforms.Resize(size=TRANSFORM_DATA_SIZE),\n",
    "\ttransforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bca9e9f4-f669-406a-83b2-a7e5eb41b403",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_CLASSES = ['Ё','А','Б','В','Г','Д','Е','Ж','З','И','Й','К','Л','М','Н','О','П','Р','С','Т','У','Ф','Х','Ц','Ч','Ш','Щ','Ъ','Ы','Ь','Э','Ю','Я']\n",
    "IMAGE_N_CLASSES = len(IMAGE_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a9d055c-7a30-4620-8d86-8326ac5df99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_and_extract_letters(filepath):\n",
    "\timage = cv.imread(filepath)\n",
    "\timage = cv.rotate(image, cv.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\timage = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "\timage = cv.medianBlur(image, 3)\n",
    "\timage = cv.adaptiveThreshold(image, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY_INV, 31, 11)\n",
    "\n",
    "\tkernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, (5, 5))\n",
    "\timage = cv.morphologyEx(image, cv.MORPH_CLOSE, kernel, iterations=3)\n",
    "\n",
    "\timage_contours, _ = cv.findContours(image, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\timage_contours = sorted(image_contours, key=lambda image_contour: cv.boundingRect(image_contour)[0])\n",
    "\n",
    "\timage_letters = []\n",
    "\tfor image_contour in image_contours:\n",
    "\t\tx, y, width, height = cv.boundingRect(image_contour)\n",
    "\t\t\n",
    "\t\tif width < 80 or height < 80:\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\tmargin = MARGIN_SIZE\n",
    "\t\timage_letter = image[y-margin:y+height+margin, x-margin:x+width+margin].copy()\n",
    "\t\timage_letter = cv.bitwise_not(image_letter)\n",
    "\t\timage_letters.append(Image.fromarray(image_letter))\n",
    "\n",
    "\treturn image_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a095b3f5-5520-4265-bd69-97aee6518a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_image_letters_step(model, transform, image_letters, image_letters_classes, image_classes):\n",
    "\tmodel.eval()\n",
    "\twith torch.inference_mode():\n",
    "\t\tfor image_letter_index, image_letter in enumerate(image_letters):\n",
    "\t\t\timage_pred = model(transform(image_letter).unsqueeze(dim=0))\n",
    "\t\t\t\n",
    "\t\t\timage_pred_class = torch.argmax(torch.softmax(image_pred, dim=1), dim=1)\n",
    "\t\t\timage_pred_class = image_classes[image_pred_class]\n",
    "\t\t\t\n",
    "\t\t\timage_letter_class = image_letters_classes[image_letter_index]\n",
    "\t\t\tprint(image_letter_class, '=', image_pred_class, end=', ')\n",
    "\tprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3b65f5b-fe5c-4947-a021-b8287619b884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TinyVGG 64x64\n",
    "class TinyVGG_64x64(nn.Module):\n",
    "    \"\"\"\n",
    "    Model architecture copying TinyVGG from: \n",
    "    https://poloclub.github.io/cnn-explainer/\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: int, hidden_units: int, out_features: int) -> None:\n",
    "        super().__init__()\n",
    "        self.tinymodel = nn.Sequential(\n",
    "            # tinymodel conv2d block 1\n",
    "\t\t\tnn.Conv2d(in_channels, hidden_units, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "\t\t\t# tinymodel conv2d block 1\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\t\t\t\n",
    "\t        # tinymodel classifier block\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(hidden_units*16*16, out_features)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.tinymodel(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30742165-457d-40cd-9b8d-91b95c4f9c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_letters = read_image_and_extract_letters('IMG.JPG')\n",
    "image_letters_classes = ['А', 'В', 'Г', 'К', 'М', 'Н', 'Е']\n",
    "image_n_letters = len(image_letters_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d50cefe-bac4-49fa-bf45-94997b95c5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TinyVGG_64x64(in_channels=3, hidden_units=HIDDEN_UNITS, out_features=IMAGE_N_CLASSES)\n",
    "model.load_state_dict(torch.load(f='TinyVGG_P20_H96_64x64.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26555938-21f6-4e8d-b94d-194de4707806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "А = А, В = В, Г = Г, К = К, М = М, Н = Н, Е = Е, \n"
     ]
    }
   ],
   "source": [
    "test_image_letters_step(model, LETTERS_TRANSFORM, image_letters, image_letters_classes, IMAGE_CLASSES)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
